{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir), 'Arxiv')\n",
    "sys.path.insert(0, path)\n",
    "from Arxiv import Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_path = os.getcwd()\n",
    "categories_path = os.path.join(categories_path, 'query_information', 'categories.txt')\n",
    "\n",
    "authors_path = os.getcwd()\n",
    "authors_path = os.path.join(authors_path, 'query_information', 'authors.txt')\n",
    "\n",
    "key_phrases_path = os.getcwd()\n",
    "key_phrases_path = os.path.join(key_phrases_path, 'query_information', 'key_phrases.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(au:Goodfellow OR au:McInnes) OR (cat:cond-mat.dis-nn OR cat:cs.AI OR cat:cs.CV OR cat:ds.CB OR cat:cs.DC OR cat:cs.GL OR cat:cs.IT OR cat:cs.LG OR cat:cs.NA OR cat:cs.PL OR cat:stat.AP OR cat:stat.CO OR cat:stat.ME OR cat:stat.ML OR cat:stat.OT OR cat:stat.TH OR cat:eess.AS)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query_string = Arxiv.search_query(categories=categories_path, authors=authors_path)\n",
    "search_query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arxiv_example = Arxiv(number_of_repeats=4, max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T16:54:17Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T16:54:17Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Speech2Face: Learning the Face Behind a Voice',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Speech2Face: Learning the Face Behind a Voice'},\n",
       "  'summary': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\"},\n",
       "  'authors': ['Tae-Hyun Oh',\n",
       "   'Tali Dekel',\n",
       "   'Changil Kim',\n",
       "   'Inbar Mosseri',\n",
       "   'William T. Freeman',\n",
       "   'Michael Rubinstein',\n",
       "   'Wojciech Matusik'],\n",
       "  'author_detail': {'name': 'Wojciech Matusik'},\n",
       "  'author': 'Wojciech Matusik',\n",
       "  'arxiv_comment': 'To appear in CVPR2019. Project page: http://speech2face.github.io',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09773v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.CV',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.MM',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbrächter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example._generate_papers(search_query_string)\n",
    "Arxiv_example.queried_papers_unfiltered[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T16:54:17Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T16:54:17Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Speech2Face: Learning the Face Behind a Voice',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Speech2Face: Learning the Face Behind a Voice'},\n",
       "  'summary': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\"},\n",
       "  'authors': ['Tae-Hyun Oh',\n",
       "   'Tali Dekel',\n",
       "   'Changil Kim',\n",
       "   'Inbar Mosseri',\n",
       "   'William T. Freeman',\n",
       "   'Michael Rubinstein',\n",
       "   'Wojciech Matusik'],\n",
       "  'author_detail': {'name': 'Wojciech Matusik'},\n",
       "  'author': 'Wojciech Matusik',\n",
       "  'arxiv_comment': 'To appear in CVPR2019. Project page: http://speech2face.github.io',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09773v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.CV',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.MM',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbrächter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example._filter_papers_time(search_query_string)\n",
    "Arxiv_example.query_results_filtered_date[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T16:54:17Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T16:54:17Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Speech2Face: Learning the Face Behind a Voice',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Speech2Face: Learning the Face Behind a Voice'},\n",
       "  'summary': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\"},\n",
       "  'authors': ['Tae-Hyun Oh',\n",
       "   'Tali Dekel',\n",
       "   'Changil Kim',\n",
       "   'Inbar Mosseri',\n",
       "   'William T. Freeman',\n",
       "   'Michael Rubinstein',\n",
       "   'Wojciech Matusik'],\n",
       "  'author_detail': {'name': 'Wojciech Matusik'},\n",
       "  'author': 'Wojciech Matusik',\n",
       "  'arxiv_comment': 'To appear in CVPR2019. Project page: http://speech2face.github.io',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09773v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.CV',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.MM',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbrächter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T16:54:17Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T16:54:17Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=54, tm_sec=17, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Speech2Face: Learning the Face Behind a Voice',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Speech2Face: Learning the Face Behind a Voice'},\n",
       "  'summary': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"How much can we infer about a person's looks from the way they speak? In this\\npaper, we study the task of reconstructing a facial image of a person from a\\nshort audio recording of that person speaking. We design and train a deep\\nneural network to perform this task using millions of natural Internet/YouTube\\nvideos of people speaking. During training, our model learns voice-face\\ncorrelations that allow it to produce images that capture various physical\\nattributes of the speakers such as age, gender and ethnicity. This is done in a\\nself-supervised manner, by utilizing the natural co-occurrence of faces and\\nspeech in Internet videos, without the need to model attributes explicitly. We\\nevaluate and numerically quantify how--and in what manner--our Speech2Face\\nreconstructions, obtained directly from audio, resemble the true face images of\\nthe speakers.\"},\n",
       "  'authors': ['Tae-Hyun Oh',\n",
       "   'Tali Dekel',\n",
       "   'Changil Kim',\n",
       "   'Inbar Mosseri',\n",
       "   'William T. Freeman',\n",
       "   'Michael Rubinstein',\n",
       "   'Wojciech Matusik'],\n",
       "  'author_detail': {'name': 'Wojciech Matusik'},\n",
       "  'author': 'Wojciech Matusik',\n",
       "  'arxiv_comment': 'To appear in CVPR2019. Project page: http://speech2face.github.io',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09773v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.CV',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.MM',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09773v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09773v1',\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09791v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:31:40Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=31, tm_sec=40, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:31:40Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=31, tm_sec=40, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Multi-relational Poincaré Graph Embeddings',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Multi-relational Poincaré Graph Embeddings'},\n",
       "  'summary': 'Hyperbolic embeddings have recently gained attention in machine learning due\\nto their ability to represent hierarchical data more accurately and succinctly\\nthan their Euclidean analogues. However, multi-relational knowledge graphs\\noften exhibit multiple simultaneous hierarchies, which current hyperbolic\\nmodels do not capture. To address this, we propose a model that embeds\\nmulti-relational graph data in the Poincar\\\\\\'e ball model of hyperbolic space.\\nOur Multi-Relational Poincar\\\\\\'e model (MuRP) learns relation-specific\\nparameters to transform entity embeddings by M\\\\\"obius matrix-vector\\nmultiplication and M\\\\\"obius addition. Experiments on the hierarchical WN18RR\\nknowledge graph show that our multi-relational Poincar\\\\\\'e embeddings outperform\\ntheir Euclidean counterpart and existing embedding methods on the link\\nprediction task, particularly at lower dimensionality.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Hyperbolic embeddings have recently gained attention in machine learning due\\nto their ability to represent hierarchical data more accurately and succinctly\\nthan their Euclidean analogues. However, multi-relational knowledge graphs\\noften exhibit multiple simultaneous hierarchies, which current hyperbolic\\nmodels do not capture. To address this, we propose a model that embeds\\nmulti-relational graph data in the Poincar\\\\\\'e ball model of hyperbolic space.\\nOur Multi-Relational Poincar\\\\\\'e model (MuRP) learns relation-specific\\nparameters to transform entity embeddings by M\\\\\"obius matrix-vector\\nmultiplication and M\\\\\"obius addition. Experiments on the hierarchical WN18RR\\nknowledge graph show that our multi-relational Poincar\\\\\\'e embeddings outperform\\ntheir Euclidean counterpart and existing embedding methods on the link\\nprediction task, particularly at lower dimensionality.'},\n",
       "  'authors': ['Ivana Balažević', 'Carl Allen', 'Timothy Hospedales'],\n",
       "  'author_detail': {'name': 'Timothy Hospedales'},\n",
       "  'author': 'Timothy Hospedales',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09791v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09791v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09791v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09791v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09780v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:08:49Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=8, tm_sec=49, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:08:49Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=8, tm_sec=49, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Bayesian Optimization over Sets',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Bayesian Optimization over Sets'},\n",
       "  'summary': 'We propose a Bayesian optimization method over sets, to minimize a black-box\\nfunction that can take a set as single input. Because set inputs are\\npermutation-invariant and variable-length, traditional Gaussian process-based\\nBayesian optimization strategies which assume vector inputs can fall short. To\\naddress this, we develop a Bayesian optimization method with \\\\emph{set kernel}\\nthat is used to build surrogate functions. This kernel accumulates similarity\\nover set elements to enforce permutation-invariance and permit sets of variable\\nsize, but this comes at a greater computational cost. To reduce this burden, we\\npropose a more efficient probabilistic approximation which we prove is still\\npositive definite and is an unbiased estimator of the true set kernel. Finally,\\nwe present several numerical experiments which demonstrate that our method\\noutperforms other methods in various applications.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'We propose a Bayesian optimization method over sets, to minimize a black-box\\nfunction that can take a set as single input. Because set inputs are\\npermutation-invariant and variable-length, traditional Gaussian process-based\\nBayesian optimization strategies which assume vector inputs can fall short. To\\naddress this, we develop a Bayesian optimization method with \\\\emph{set kernel}\\nthat is used to build surrogate functions. This kernel accumulates similarity\\nover set elements to enforce permutation-invariance and permit sets of variable\\nsize, but this comes at a greater computational cost. To reduce this burden, we\\npropose a more efficient probabilistic approximation which we prove is still\\npositive definite and is an unbiased estimator of the true set kernel. Finally,\\nwe present several numerical experiments which demonstrate that our method\\noutperforms other methods in various applications.'},\n",
       "  'authors': ['Jungtaek Kim',\n",
       "   'Michael McCourt',\n",
       "   'Tackgeun You',\n",
       "   'Saehoon Kim',\n",
       "   'Seungjin Choi'],\n",
       "  'author_detail': {'name': 'Seungjin Choi'},\n",
       "  'author': 'Seungjin Choi',\n",
       "  'arxiv_comment': '14 pages, 4 figures, 3 tables',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09780v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09780v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'stat.ML',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09780v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09780v1',\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example.arxiv_papers(search_query_string)\n",
    "Arxiv_example.fav_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
