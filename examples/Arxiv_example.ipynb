{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir), 'Arxiv')\n",
    "sys.path.insert(0, path)\n",
    "from Arxiv import Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_path = os.getcwd()\n",
    "categories_path = os.path.join(categories_path, 'query_information', 'categories.txt')\n",
    "\n",
    "authors_path = os.getcwd()\n",
    "authors_path = os.path.join(authors_path, 'query_information', 'authors.txt')\n",
    "\n",
    "key_phrases_path = os.getcwd()\n",
    "key_phrases_path = os.path.join(key_phrases_path, 'query_information', 'key_phrases.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(au:Goodfellow OR au:McInnes) OR (cat:cond-mat.dis-nn OR cat:cs.AI OR cat:cs.CV OR cat:ds.CB OR cat:cs.DC OR cat:cs.GL OR cat:cs.IT OR cat:cs.LG OR cat:cs.NA OR cat:cs.PL OR cat:stat.AP OR cat:stat.CO OR cat:stat.ME OR cat:stat.ML OR cat:stat.OT OR cat:stat.TH OR cat:eess.AS)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query_string = Arxiv.search_query(categories=categories_path, authors=authors_path)\n",
    "search_query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arxiv_example = Arxiv(number_of_repeats=4, max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbr√§chter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:56:52Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:56:52Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies'},\n",
       "  'summary': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\"},\n",
       "  'authors': ['Xue Bin Peng',\n",
       "   'Michael Chang',\n",
       "   'Grace Zhang',\n",
       "   'Pieter Abbeel',\n",
       "   'Sergey Levine'],\n",
       "  'author_detail': {'name': 'Sergey Levine'},\n",
       "  'author': 'Sergey Levine',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09808v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example._generate_papers(search_query_string)\n",
    "Arxiv_example.queried_papers_unfiltered[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbr√§chter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:56:52Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:56:52Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies'},\n",
       "  'summary': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\"},\n",
       "  'authors': ['Xue Bin Peng',\n",
       "   'Michael Chang',\n",
       "   'Grace Zhang',\n",
       "   'Pieter Abbeel',\n",
       "   'Sergey Levine'],\n",
       "  'author_detail': {'name': 'Sergey Levine'},\n",
       "  'author': 'Sergey Levine',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09808v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example._filter_papers_time(search_query_string)\n",
    "Arxiv_example.query_results_filtered_date[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbr√§chter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:56:52Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:56:52Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=56, tm_sec=52, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'MCP: Learning Composable Hierarchical Control with Multiplicative\\n  Compositional Policies'},\n",
       "  'summary': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\",\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': \"Humans are able to perform a myriad of sophisticated tasks by drawing upon\\nskills acquired through prior experience. For autonomous agents to have this\\ncapability, they must be able to extract reusable skills from past experience\\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\\ntasks often require coordination of multiple skills simultaneously. Learning\\ndiscrete primitives for every combination of skills quickly becomes\\nprohibitive. Composable primitives that can be recombined to create a large\\nvariety of behaviors can be more suitable for modeling this combinatorial\\nexplosion. In this work, we propose multiplicative compositional policies\\n(MCP), a method for learning reusable motor skills that can be composed to\\nproduce a range of complex behaviors. Our method factorizes an agent's skills\\ninto a collection of primitives, where multiple primitives can be activated\\nsimultaneously via multiplicative composition. This flexibility allows the\\nprimitives to be transferred and recombined to elicit new behaviors as\\nnecessary for novel tasks. We demonstrate that MCP is able to extract\\ncomposable skills for highly complex simulated characters from pre-training\\ntasks, such as motion imitation, and then reuse these skills to solve\\nchallenging continuous control tasks, such as dribbling a soccer ball to a\\ngoal, and picking up an object and transporting it to a target location.\"},\n",
       "  'authors': ['Xue Bin Peng',\n",
       "   'Michael Chang',\n",
       "   'Grace Zhang',\n",
       "   'Pieter Abbeel',\n",
       "   'Sergey Levine'],\n",
       "  'author_detail': {'name': 'Sergey Levine'},\n",
       "  'author': 'Sergey Levine',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09808v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09808v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09808v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:53:08Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:53:08Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=53, tm_sec=8, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'How degenerate is the parametrization of neural networks with the ReLU\\n  activation function?'},\n",
       "  'summary': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Neural network training is usually accomplished by solving a non-convex\\noptimization problem using stochastic gradient descent. Although one optimizes\\nover the networks parameters, the loss function generally only depends on the\\nrealization of a neural network, i.e. the function it computes. Studying the\\nfunctional optimization problem over the space of realizations can open up\\ncompletely new ways to understand neural network training. In particular, usual\\nloss functions like the mean squared error are convex on sets of neural network\\nrealizations, which themselves are non-convex. Note, however, that each\\nrealization has many different, possibly degenerate, parametrizations. In\\nparticular, a local minimum in the parametrization space needs not correspond\\nto a local minimum in the realization space. To establish such a connection,\\ninverse stability of the realization map is required, meaning that proximity of\\nrealizations must imply proximity of corresponding parametrizations. In this\\npaper we present pathologies which prevent inverse stability in general, and\\nproceed to establish a restricted set of parametrizations on which we have\\ninverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by\\noptimizing over such restricted sets, it is still possible to learn any\\nfunction, which can be learned by optimization over unrestricted sets. While\\nmost of this paper focuses on shallow networks, none of methods used are, in\\nprinciple, limited to shallow networks, and it should be possible to extend\\nthem to deep neural networks.'},\n",
       "  'authors': ['Julius Berner', 'Dennis Elbr√§chter', 'Philipp Grohs'],\n",
       "  'author_detail': {'name': 'Philipp Grohs'},\n",
       "  'author': 'Philipp Grohs',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09803v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.FA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09803v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09803v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09753v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T16:19:04Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=19, tm_sec=4, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T16:19:04Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=16, tm_min=19, tm_sec=4, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'An embedded--hybridized discontinuous Galerkin method for the coupled\\n  Stokes--Darcy system',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'An embedded--hybridized discontinuous Galerkin method for the coupled\\n  Stokes--Darcy system'},\n",
       "  'summary': 'We introduce an embedded--hybridized discontinuous Galerkin (EDG--HDG) method\\nfor the coupled Stokes--Darcy system. This EDG--HDG method is a pointwise\\nmass-conserving discretization resulting in a divergence-conforming velocity\\nfield on the whole domain. In the proposed scheme, coupling between the Stokes\\nand Darcy domains is achieved naturally through the EDG--HDG facet variables.\\n\\\\emph{A priori} error analysis shows optimal convergence rates, and that the\\nvelocity error does not depend on the pressure. The error analysis is verified\\nthrough numerical examples on unstructured grids for different orders of\\npolynomial approximation.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=10&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'We introduce an embedded--hybridized discontinuous Galerkin (EDG--HDG) method\\nfor the coupled Stokes--Darcy system. This EDG--HDG method is a pointwise\\nmass-conserving discretization resulting in a divergence-conforming velocity\\nfield on the whole domain. In the proposed scheme, coupling between the Stokes\\nand Darcy domains is achieved naturally through the EDG--HDG facet variables.\\n\\\\emph{A priori} error analysis shows optimal convergence rates, and that the\\nvelocity error does not depend on the pressure. The error analysis is verified\\nthrough numerical examples on unstructured grids for different orders of\\npolynomial approximation.'},\n",
       "  'authors': ['Aycil Cesmelioglu', 'Sander Rhebergen', 'Garth N. Wells'],\n",
       "  'author_detail': {'name': 'Garth N. Wells'},\n",
       "  'author': 'Garth N. Wells',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09753v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09753v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'math.NA',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'math.NA',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None},\n",
       "   {'term': '65N12, 65N15, 65N30, 76D07, 76S99',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09753v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09753v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None},\n",
       " {'id': 'http://arxiv.org/abs/1905.09796v1',\n",
       "  'guidislink': True,\n",
       "  'updated': '2019-05-23T17:39:23Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=39, tm_sec=23, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'published': '2019-05-23T17:39:23Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=23, tm_hour=17, tm_min=39, tm_sec=23, tm_wday=3, tm_yday=143, tm_isdst=0),\n",
       "  'title': 'Augmenting correlation structures in spatial data using deep generative\\n  models',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'Augmenting correlation structures in spatial data using deep generative\\n  models'},\n",
       "  'summary': 'State-of-the-art deep learning methods have shown a remarkable capacity to\\nmodel complex data domains, but struggle with geospatial data. In this paper,\\nwe introduce SpaceGAN, a novel generative model for geospatial domains that\\nlearns neighbourhood structures through spatial conditioning. We propose to\\nenhance spatial representation beyond mere spatial coordinates, by conditioning\\neach data point on feature vectors of its spatial neighbours, thus allowing for\\na more flexible representation of the spatial structure. To overcome issues of\\ntraining convergence, we employ a metric capturing the loss in local spatial\\nautocorrelation between real and generated data as stopping criterion for\\nSpaceGAN parametrization. This way, we ensure that the generator produces\\nsynthetic samples faithful to the spatial patterns observed in the input.\\nSpaceGAN is successfully applied for data augmentation and outperforms compared\\nto other methods of synthetic spatial data generation. Finally, we propose an\\nensemble learning framework for the geospatial domain, taking augmented\\nSpaceGAN samples as training data for a set of ensemble learners. We\\nempirically show the superiority of this approach over conventional ensemble\\nlearning approaches and rivaling spatial data augmentation methods, using\\nsynthetic and real-world prediction tasks. Our findings suggest that SpaceGAN\\ncan be used as a tool for (1) artificially inflating sparse geospatial data and\\n(2) improving generalization of geospatial models.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://export.arxiv.org/api/query?search_query=%28au%3AGoodfellow+OR+au%3AMcInnes%29+OR+%28cat%3Acond-mat.dis-nn+OR+cat%3Acs.AI+OR+cat%3Acs.CV+OR+cat%3Ads.CB+OR+cat%3Acs.DC+OR+cat%3Acs.GL+OR+cat%3Acs.IT+OR+cat%3Acs.LG+OR+cat%3Acs.NA+OR+cat%3Acs.PL+OR+cat%3Astat.AP+OR+cat%3Astat.CO+OR+cat%3Astat.ME+OR+cat%3Astat.ML+OR+cat%3Astat.OT+OR+cat%3Astat.TH+OR+cat%3Aeess.AS%29&id_list=&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending',\n",
       "   'value': 'State-of-the-art deep learning methods have shown a remarkable capacity to\\nmodel complex data domains, but struggle with geospatial data. In this paper,\\nwe introduce SpaceGAN, a novel generative model for geospatial domains that\\nlearns neighbourhood structures through spatial conditioning. We propose to\\nenhance spatial representation beyond mere spatial coordinates, by conditioning\\neach data point on feature vectors of its spatial neighbours, thus allowing for\\na more flexible representation of the spatial structure. To overcome issues of\\ntraining convergence, we employ a metric capturing the loss in local spatial\\nautocorrelation between real and generated data as stopping criterion for\\nSpaceGAN parametrization. This way, we ensure that the generator produces\\nsynthetic samples faithful to the spatial patterns observed in the input.\\nSpaceGAN is successfully applied for data augmentation and outperforms compared\\nto other methods of synthetic spatial data generation. Finally, we propose an\\nensemble learning framework for the geospatial domain, taking augmented\\nSpaceGAN samples as training data for a set of ensemble learners. We\\nempirically show the superiority of this approach over conventional ensemble\\nlearning approaches and rivaling spatial data augmentation methods, using\\nsynthetic and real-world prediction tasks. Our findings suggest that SpaceGAN\\ncan be used as a tool for (1) artificially inflating sparse geospatial data and\\n(2) improving generalization of geospatial models.'},\n",
       "  'authors': ['Konstantin Klemmer',\n",
       "   'Adriano Koshiyama',\n",
       "   'Sebastian Flennerhag'],\n",
       "  'author_detail': {'name': 'Sebastian Flennerhag'},\n",
       "  'author': 'Sebastian Flennerhag',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/1905.09796v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/1905.09796v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None},\n",
       "   {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}],\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1905.09796v1',\n",
       "  'affiliation': 'None',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.09796v1',\n",
       "  'arxiv_comment': None,\n",
       "  'journal_reference': None,\n",
       "  'doi': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arxiv_example.arxiv_papers(search_query_string)\n",
    "Arxiv_example.fav_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "outputs = os.path.join(os.getcwd(), 'ouputs')\n",
    "\n",
    "if not os.path.exists(outputs):\n",
    "    os.mkdir(outputs)\n",
    "\n",
    "Arxiv_example._download_papers(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
